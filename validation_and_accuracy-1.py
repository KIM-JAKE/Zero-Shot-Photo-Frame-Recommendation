# -*- coding: utf-8 -*-
"""Validation_and_Accuracy

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R2kZ2SLOTgWt2CtSJEPNYshjiApdefRg
"""

from google.colab import drive
drive.mount('Validation_and_Accuracy')

import cv2
import numpy as np
import os
from PIL import Image
import matplotlib.pyplot as plt
from sklearn.cluster import AgglomerativeClustering
from scipy.cluster.hierarchy import dendrogram
from sklearn.preprocessing import StandardScaler
import torch
from torchvision import transforms

"""이미지는 모두 256*256에 맞추어 프레임 제작 (계층적 군집화의 시간복잡도 이슈)

"""

import cv2
import numpy as np
import os
from PIL import Image

#히스토그램으로 만들어줌

def load_and_preprocess_image(path):
    img = cv2.imread(path)
    pil_img = Image.fromarray(img)
    resized_img = pil_img.resize((256, 256), Image.LANCZOS)
    # PIL 이미지를 NumPy 배열로 변환
    resized_img_np = np.array(resized_img)
    # OpenCV는 BGR 형식을 사용하므로 색상 순서를 변경
    resized_img_np = cv2.cvtColor(resized_img_np, cv2.COLOR_RGB2BGR)
    hsv = cv2.cvtColor(resized_img_np, cv2.COLOR_BGR2HSV)
    hist = cv2.calcHist([hsv], [0], None, [256], [0, 256])
    cv2.normalize(hist, hist, 0, 1, cv2.NORM_MINMAX)
    return hist

def load_images_from_folder(folder_path):
    images = []
    for filename in os.listdir(folder_path):
        img = load_and_preprocess_image(os.path.join(folder_path, filename))
        if img is not None:
            images.append(img)
    return images


def load_and_preprocess_photo(path):
    # 이미지를 불러오고 원하는 방식으로 전처리하는 함수
    img = cv2.imread(path)
    img = cv2.resize(img, (256, 256))  # 예시: 이미지 크기 조정
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    # 추가 전처리 작업들...
    return img

def load_photos_from_folder(folder_path):
    images = []
    for filename in os.listdir(folder_path):
        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):  # 이미지 파일만 처리
            img = load_and_preprocess_photo(os.path.join(folder_path, filename))
            if img is not None:
                images.append(img)
    return images


# 유사도 계산 함수
def calculate_similarity_by_corr(hist1, hist2, method=cv2.HISTCMP_CORREL):
    return cv2.compareHist(hist1, hist2, method)

def calculate_similarity_by_bhat(hist1, hist2, method=cv2.HISTCMP_BHATTACHARYYA):
    return cv2.compareHist(hist1, hist2, method)

"""# 1. 제작해 놓은 프레임과 유사도가 높은 것을 선별 후 프레임 합성"""

base_path = '/content/Validation_and_Accuracy/MyDrive/validation_image'  # 이미지 폴더 경로 수정

categories = os.listdir(base_path)


City_real_images_path = os.path.join(base_path,  'city')
City_k_frame_images_path = os.path.join(base_path,  'city frame/k')
City_hi_frame_images_path = os.path.join(base_path,  'city frame/hi')

City_real_images = load_images_from_folder(City_real_images_path)
City_k_frame_images = load_images_from_folder(City_k_frame_images_path)
City_hi_frame_images = load_images_from_folder(City_hi_frame_images_path)
City_Frame_images = City_k_frame_images + City_hi_frame_images

Ocean_real_images_path = os.path.join(base_path,  'ocean')
Ocean_k_frame_images_path = os.path.join(base_path,  'ocean frame/k')
Ocean_hi_frame_images_path = os.path.join(base_path,  'ocean frame/hi')

Ocean_real_images = load_images_from_folder(Ocean_real_images_path)
Ocean_k_frame_images = load_images_from_folder(Ocean_k_frame_images_path)
Ocean_hi_frame_images = load_images_from_folder(Ocean_hi_frame_images_path)
Ocean_Frame_images = Ocean_k_frame_images + Ocean_hi_frame_images

desert_real_images_path = os.path.join(base_path,  'desert')
desert_k_frame_images_path = os.path.join(base_path,  'desert frame/k')
desert_hi_frame_images_path = os.path.join(base_path,  'desert frame/hi')

desert_real_images = load_images_from_folder(desert_real_images_path)
desert_k_frame_images = load_images_from_folder(desert_k_frame_images_path)
desert_hi_frame_images = load_images_from_folder(desert_hi_frame_images_path)

desert_Frame_images = desert_k_frame_images + desert_hi_frame_images

grassland_real_images_path = os.path.join(base_path,  'grassland')
grassland_k_frame_images_path = os.path.join(base_path,  'grassland frame/k')
grassland_hi_frame_images_path = os.path.join(base_path,  'grassland frame/hi')

grassland_real_images = load_images_from_folder(grassland_real_images_path)
grassland_k_frame_images = load_images_from_folder(grassland_k_frame_images_path)
grassland_hi_frame_images = load_images_from_folder(grassland_hi_frame_images_path)

grassland_Frame_images = grassland_k_frame_images + grassland_hi_frame_images


mountain_real_images_path = os.path.join(base_path,  'mountain')
mountain_k_frame_images_path = os.path.join(base_path,  'mountain frame/k')
mountain_hi_frame_images_path = os.path.join(base_path,  'mountain frame/hi')

mountain_real_images = load_images_from_folder(mountain_real_images_path)
mountain_k_frame_images = load_images_from_folder(mountain_k_frame_images_path)
mountain_hi_frame_images = load_images_from_folder(mountain_hi_frame_images_path)

mountain_Frame_images = mountain_k_frame_images + mountain_hi_frame_images


snow_real_images_path = os.path.join(base_path,  'snow')
snow_k_frame_images_path = os.path.join(base_path,  'snow frame/k')
snow_hi_frame_images_path = os.path.join(base_path,  'snow frame/hi')

snow_real_images = load_images_from_folder(snow_real_images_path)
snow_k_frame_images = load_images_from_folder(snow_k_frame_images_path)
snow_hi_frame_images = load_images_from_folder(snow_hi_frame_images_path)

snow_Frame_images = snow_k_frame_images + snow_hi_frame_images

"""이건 사진을 저장"""

City_real_photos_path = os.path.join(base_path,  'city')
City_k_frame_photos_path = os.path.join(base_path,  'city frame/k')
City_hi_frame_photos_path = os.path.join(base_path,  'city frame/hi')

City_real_photos = load_photos_from_folder(City_real_photos_path)
City_k_frame_photos = load_photos_from_folder(City_k_frame_photos_path)
City_hi_frame_photos = load_photos_from_folder(City_hi_frame_photos_path)
City_Frame_photos = City_k_frame_photos + City_hi_frame_photos

Ocean_real_photos_path = os.path.join(base_path,  'ocean')
Ocean_k_frame_photos_path = os.path.join(base_path,  'ocean frame/k')
Ocean_hi_frame_photos_path = os.path.join(base_path,  'ocean frame/hi')

Ocean_real_photos = load_photos_from_folder(Ocean_real_photos_path)
Ocean_k_frame_photos = load_photos_from_folder(Ocean_k_frame_photos_path)
Ocean_hi_frame_photos = load_photos_from_folder(Ocean_hi_frame_photos_path)
Ocean_Frame_photos = Ocean_k_frame_photos + Ocean_hi_frame_photos

desert_real_photos_path = os.path.join(base_path,  'desert')
desert_k_frame_photos_path = os.path.join(base_path,  'desert frame/k')
desert_hi_frame_photos_path = os.path.join(base_path,  'desert frame/hi')

desert_real_photos = load_photos_from_folder(desert_real_photos_path)
desert_k_frame_photos = load_photos_from_folder(desert_k_frame_photos_path)
desert_hi_frame_photos = load_photos_from_folder(desert_hi_frame_photos_path)

desert_Frame_photos = desert_k_frame_photos + desert_hi_frame_photos

grassland_real_photos_path = os.path.join(base_path,  'grassland')
grassland_k_frame_photos_path = os.path.join(base_path,  'grassland frame/k')
grassland_hi_frame_photos_path = os.path.join(base_path,  'grassland frame/hi')

grassland_real_photos = load_photos_from_folder(grassland_real_photos_path)
grassland_k_frame_photos = load_photos_from_folder(grassland_k_frame_photos_path)
grassland_hi_frame_photos = load_photos_from_folder(grassland_hi_frame_photos_path)

grassland_Frame_photos = grassland_k_frame_photos + grassland_hi_frame_photos


mountain_real_photos_path = os.path.join(base_path,  'mountain')
mountain_k_frame_photos_path = os.path.join(base_path,  'mountain frame/k')
mountain_hi_frame_photos_path = os.path.join(base_path,  'mountain frame/hi')

mountain_real_photos = load_photos_from_folder(mountain_real_photos_path)
mountain_k_frame_photos = load_photos_from_folder(mountain_k_frame_photos_path)
mountain_hi_frame_photos = load_photos_from_folder(mountain_hi_frame_photos_path)

mountain_Frame_photos = mountain_k_frame_photos + mountain_hi_frame_photos


snow_real_photos_path = os.path.join(base_path,  'snow')
snow_k_frame_photos_path = os.path.join(base_path,  'snow frame/k')
snow_hi_frame_photos_path = os.path.join(base_path,  'snow frame/hi')

snow_real_photos = load_photos_from_folder(snow_real_photos_path)
snow_k_frame_photos = load_photos_from_folder(snow_k_frame_photos_path)
snow_hi_frame_photos = load_photos_from_folder(snow_hi_frame_photos_path)

snow_Frame_photos = snow_k_frame_photos + snow_hi_frame_photos

# Plotting the image
plt.imshow(snow_real_photos[0])
plt.colorbar()
plt.show()

"""threshold 할 때와 달라진 점 ! our_frames를 만들어 모든 프레임 후보를 저장해놓는다.이후 유사도를 계산하여 가장 높은 이미지를 프레임으로 만들어 출력해줄 것이다. our_frames와 valid_images는 모두 히스토그램이다.

images = histogram

photos = 진짜 사진
"""

our_frames = City_Frame_images + Ocean_Frame_images + desert_Frame_images + grassland_Frame_images + mountain_Frame_images + snow_Frame_images

valid_images = City_real_images  + Ocean_real_images + desert_real_images + grassland_real_images + mountain_real_images + snow_real_images

our_photos_frames = City_Frame_photos + Ocean_Frame_photos + desert_Frame_photos + grassland_Frame_photos + mountain_Frame_photos + snow_Frame_photos

valid_photos = City_real_photos  + Ocean_real_photos + desert_real_photos + grassland_real_photos + mountain_real_photos + snow_real_photos

len(our_frames), len(valid_images)

len(our_photos_frames), len(valid_photos)

valid_images[0].shape, valid_photos[0].shape

def find_most_similar(frames, images, threshold=0.5):
    most_similar_per_image = []

    for img_index, img in enumerate(images):
        max_similarity = 0
        most_similar_frame_index = -1  # 인덱스 초기화

        for frame_index, frame in enumerate(frames):
            similarity = calculate_similarity_by_corr(frame, img)

            if similarity > max_similarity:
                max_similarity = similarity
                most_similar_frame_index = frame_index

        if max_similarity < threshold:
            most_similar_per_image.append((img_index, None))
        else:
            most_similar_per_image.append((img_index, most_similar_frame_index))

    return most_similar_per_image

def plot_similar_images(our_photos_frames, valid_photos, similar_frames_indices):
    cnt = 0
    for valid_index, frame_index in similar_frames_indices:
        if frame_index is not None:
            cnt+=1
            plt.figure(figsize=(10, 5))
            # 첫 번째 서브플롯: valid_images의 이미지
            plt.subplot(1, 2, 1)
            plt.imshow(valid_photos[valid_index])
            plt.title(f'Valid Image {valid_index}')

            # 두 번째 서브플롯: our_photos_frames의 가장 유사한 이미지
            plt.subplot(1, 2, 2)
            plt.imshow(our_photos_frames[frame_index])
            plt.title(f'Most Similar Frame {frame_index}')

            plt.show()

    print("총 이미지 추천 횟수는",cnt,"입니다.")
    print("이 외에는 유사한 프레임이 없습니다.")

# 가장 유사한 프레임 찾기
most_similar_frames = find_most_similar(our_frames, valid_images)

# 결과 출력 및 서브플롯 생성
plot_similar_images(our_photos_frames, valid_photos, most_similar_frames)



def calculate_tp_fp(most_similar_per_image):
    category_counts = {'City': {'TP': 0, 'FP': 0},
                       'Ocean': {'TP': 0, 'FP': 0},
                       'Desert': {'TP': 0, 'FP': 0},
                       'Grassland': {'TP': 0, 'FP': 0},
                       'Mountain': {'TP': 0, 'FP': 0},
                       'Snow': {'TP': 0, 'FP': 0}}

    for img_index, frame_index in most_similar_per_image:
        if frame_index is None:
            continue  # 해당하는 frame이 없는 경우는 무시

        # 카테고리 찾기
        img_category = img_index // 20
        frame_category = frame_index // 10

        # 카테고리별 True Positive와 False Positive 계산
        if img_category == frame_category:
            category_name = list(category_counts.keys())[img_category]
            category_counts[category_name]['TP'] += 1
        else:
            category_name = list(category_counts.keys())[frame_category]
            category_counts[category_name]['FP'] += 1

    return category_counts

# 예시 most_similar_per_image 리스트
# most_similar_per_image = [(0, 9), (1, 11), (30, 35), ...]

# TP와 FP 계산
tp_fp_counts = calculate_tp_fp(find_most_similar(our_frames, valid_images,0.5))
print(tp_fp_counts)



"""
Confusion matrix를 만들기 위해서는 True Positive (TP), False Positive (FP), True Negative (TN), False Negative (FN)의 값을 알아야 합니다. 이미 TP와 FP는 계산된 상태이므로, TN과 FN을 계산해야 합니다.

각 카테고리에 대해 다음을 고려해야 합니다:

True Positive (TP): 실제와 예측이 모두 해당 카테고리인 경우의 수.
False Positive (FP): 예측이 해당 카테고리이지만 실제는 다른 카테고리인 경우의 수.
True Negative (TN): 실제와 예측 모두 해당 카테고리가 아닌 경우의 수.
False Negative (FN): 실제가 해당 카테고리이지만 예측이 다른 카테고리인 경우의 수.
"""

categories = ['City', 'Ocean', 'Desert', 'Grassland', 'Mountain', 'Snow']
tp_fp_counts = calculate_tp_fp(find_most_similar(our_frames, valid_images,0.5))

def conf(diction,categories) :
  # 각 카테고리에 대해 FN과 TN 계산


  # 전체 Confusion Matrix를 만들기 위해 TP, FP, FN, TN의 합계 계산
  total_tp = sum([diction[cat]['TP'] for cat in categories])
  total_fp = sum([diction[cat]['FP'] for cat in categories])


  confusion_matrix = {
      'TP': total_tp,
      'FP': total_fp,
      'FN': 0,
      'TN': 0
  }

  return (confusion_matrix)

cf = conf(tp_fp_counts ,categories)

cf

"""TP와 FP만 사용"""

import seaborn as sns

def plot_confusion_matrix(confusion_matrix):
    # Confusion Matrix를 히트맵으로 변환
    cm_array = [[confusion_matrix['TP'], confusion_matrix['FP']]
                ]

    labels = ['True Positive', 'False Positive', 'False Negative', 'True Negative']
    sns.heatmap(cm_array, annot=True, fmt='d', cmap='Blues_r', xticklabels=['Positive', 'Negative'], yticklabels=['Positive'])

    plt.title('Confusion Matrix')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()


# Confusion Matrix 시각화
plot_confusion_matrix(cf)

"""FN과 TN도 사용"""

import seaborn as sns

def plot_confusion_matrix_N(confusion_matrix):
    # Confusion Matrix를 히트맵으로 변환
    cm_array = [[confusion_matrix['TP'], confusion_matrix['FP']],
                [confusion_matrix['FN'], confusion_matrix['TN']]]

    labels = ['True Positive', 'False Positive', 'False Negative', 'True Negative']
    sns.heatmap(cm_array, annot=True, fmt='d', cmap='Blues', xticklabels=['Positive', 'Negative'], yticklabels=['Positive', 'Negative'])

    plt.title('Confusion Matrix')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()


# Confusion Matrix 시각화
plot_confusion_matrix(cf)

def calculate_accuracy(tp, fp, fn, tn):
    total = tp + fp + fn + tn
    if total == 0:
        return 0
    return (tp + tn) / total

def calculate_f1_score(tp, fp, fn):
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    if (precision + recall) == 0:
        return 0
    return 2 * (precision * recall) / (precision + recall)

# 예시 데이터
tp = cf['TP']
fp = cf['FP']
fn = cf['FN']
tn = cf['TN']

# 정확도 계산
accuracy = calculate_accuracy(tp, fp, fn, tn)

# F1 스코어 계산
f1_score = calculate_f1_score(tp, fp, fn)

print(f"Accuracy: {accuracy}")
print(f"F1 Score: {f1_score}")

"""# 이제 다른 threshold로도 해보자."""

def various_th(thres) :
  msf = find_most_similar(our_frames, valid_images,thres)

  tfp = calculate_tp_fp(msf)
  print(tfp)
  cfm = conf(tfp ,categories)

  # Confusion Matrix 시각화
  plot_confusion_matrix_N(cfm)
    # 예시 데이터
  tp = cfm['TP']
  fp = cfm['FP']
  fn = cfm['FN']
  tn = cfm['TN']

  # 정확도 계산
  accuracy = calculate_accuracy(tp, fp, fn, tn)

  # F1 스코어 계산
  f1_score = calculate_f1_score(tp, fp, fn)
  print("For Threshold : ", thres)
  print(f"Accuracy: {accuracy}")
  print(f"F1 Score: {f1_score}")

for i in np.arange(0.1, 1.1, 0.1):  # 0.1부터 1.0까지 0.1씩 증가
    various_th(i)

"""0.3 이 최적의 threshold 일 것 같다는 예상과 달리, 0.6 부근에서도 정확도가 좋음. 하지만 threshold를 높일 수록 프레임 추천 양이 줄어드므로, 그닥 좋은 것도 아님.

#실전! 사진 입력하면 가장 유사한 것 추천해주기!
"""

user_path = '/content/barcel.jpg'

"""유저 이미지를 히스토그램으로"""

user_img = cv2.imread(user_path)
user_pil_img = Image.fromarray(user_img)
user_resized_img = user_pil_img.resize((256, 256), Image.LANCZOS)
# PIL 이미지를 NumPy 배열로 변환
user_resized_img_np = np.array(user_resized_img)
# OpenCV는 BGR 형식을 사용하므로 색상 순서를 변경
user_resized_img_np = cv2.cvtColor(user_resized_img_np, cv2.COLOR_RGB2BGR)
user_hsv = cv2.cvtColor(user_resized_img_np, cv2.COLOR_BGR2HSV)
user_hist = cv2.calcHist([user_hsv], [0], None, [256], [0, 256])
cv2.normalize(user_hist, user_hist, 0, 1, cv2.NORM_MINMAX)

"""이미지로"""

up = cv2.imread(user_path)
up = cv2.resize(up, (256, 256))  # 예시: 이미지 크기 조정
up = cv2.cvtColor(up, cv2.COLOR_BGR2RGB)

# 가장 유사한 프레임 찾기
user_most_similar_frames = find_most_similar(our_frames, [user_hist],0.3)

# 결과 출력 및 서브플롯 생성
plot_similar_images(our_photos_frames, [up], user_most_similar_frames)

user_most_similar_frames

# 이미지에 가운데 정사각형으로 뻥 뚫린 듯한 효과 적용
size = 200  # 정사각형의 크기
width, height = 256, 256
center_square = np.copy(our_photos_frames[(user_most_similar_frames[0][1])])
start = (width - size) // 2
end = start + size
center_square[start:end, start:end, :] = [255, 255, 255]  # 가운데 부분을 흰색으로 채우기

# 이미지 출력
plt.imshow(center_square.astype(np.uint8))
plt.axis('off')
plt.show()

from google.colab.patches import cv2_imshow

user_resized = cv2.resize(up, (200,200))

# 첫 번째 이미지에 검은색 테두리 추가
border_thickness = 10
image1_resized_with_border = cv2.copyMakeBorder(center_square, border_thickness, border_thickness, border_thickness, border_thickness, cv2.BORDER_CONSTANT, value=[0, 0, 0])

# 두 번째 이미지에 흰색 테두리 추가
border_thickness = 10
image2_resized_with_border = cv2.copyMakeBorder(user_resized, border_thickness, border_thickness, border_thickness, border_thickness, cv2.BORDER_CONSTANT, value=[255, 255, 255])

# 첫 번째 이미지에 블러 적용
image1_blurred = cv2.GaussianBlur(image1_resized_with_border, (15, 15), 0)

# 두 번째 이미지를 가운데 겹침
x_offset = (image1_blurred.shape[1] - image2_resized_with_border.shape[1]) // 2
y_offset = (image1_blurred.shape[0] - image2_resized_with_border.shape[0]) // 2

image1_blurred[y_offset:y_offset + image2_resized_with_border.shape[0], x_offset:x_offset + image2_resized_with_border.shape[1]] = image2_resized_with_border


image1_blurred = cv2.cvtColor(image1_blurred, cv2.COLOR_BGR2RGB)
# 결과 이미지를 출력
cv2_imshow(image1_blurred)

"""끝!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"""

